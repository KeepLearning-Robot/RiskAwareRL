{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"34DXrfX6rMRh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691596196448,"user_tz":300,"elapsed":747,"user":{"displayName":"David Wang","userId":"05066022198652520596"}},"outputId":"ae4caa35-2705-4291-88b2-eae89d9bff79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","PATH = '/content/gdrive/MyDrive/Risk_Aware_RL'"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1691596198041,"user":{"displayName":"David Wang","userId":"05066022198652520596"},"user_tz":300},"id":"Sumb1Zrfokae","outputId":"30f79724-2463-49af-d987-681366ca26bb","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folder: /content/gdrive/MyDrive/Risk_Aware_RL/runs_5action/prior_1/bridge_5action_Pmax0.01_CThesisDecreasing_PriorUnin_experiment20230809_154958\n","\n","#############################\n","safe_padding: True\n","number_of_runs: 1500\n","max_iterations: 400\n","discount_factor_Q: 0.9\n","alpha: 0.85\n","observation_radius: 2\n","temp: 0.005\n","prior_choice: Uninformative Prior\n","critical_threshold: 0.01\n","choice_of_C: ThesisDecreasing\n","#############################\n","\n","You want 5 tests.\n","Breakpoint will be saved every 100 steps\n"]}],"source":["#@title Initialization\n","import os\n","import time\n","import shutil\n","from tqdm import tqdm\n","import numpy as np\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n","\n","def printf(text, file_path):\n","  with open(file_path, 'a') as file:\n","      # Print to console\n","      print(text)\n","      # Write to the file\n","      file.write(text + '\\n')\n","# Experiment Parameters\n","safe_padding = True\n","\n","max_iterations = 400\n","\n","# Hyper Parameters\n","discount_factor_Q = 0.9\n","alpha = 0.85\n","observation_radius = 2\n","temp = 0.005\n","choice_of_C = \"ThesisDecreasing\"\n","\n","# # Choice of Prior\n","prior_choice = \"Uninformative Prior\" #@param [\"Uninformative Prior\", \"Medium Informative Prior\", \"High Informative Prior\"] {allow-input:false}\n","pc = None\n","\n","\n","\n","if prior_choice == \"Uninformative Prior\":\n","    # critical_threshold = 0.33\n","    critical_threshold = 0.01\n","    pc = \"1\"\n","elif prior_choice == \"Medium Informative Prior\":\n","    critical_threshold = 0.01\n","    pc = \"2\"\n","elif prior_choice == \"High Informative Prior\":\n","    critical_threshold = 0.0033\n","    # critical_threshold = 0.01\n","    pc = \"3\"\n","else:\n","    raise Exception(\"NotImplemented\")\n","\n","if safe_padding:\n","  folder_name = \"bridge_5action_Pmax{Pmax}_C{C}_Prior{prior}_experiment\".format(\n","          Pmax=critical_threshold, prior=prior_choice[0:4], C=choice_of_C)\n","  if prior_choice != \"Uninformative Prior\" and critical_threshold != 0.01:\n","    number_of_runs = 500\n","  else:\n","    number_of_runs = 1500\n","else:\n","  folder_name = \"Q_Learning_Only_\"\n","  number_of_runs = 1500\n","\n","# pc_dict = {\n","#     1: [\"Uninformative Prior\", 0.33, \"1\"],\n","#     2: [\"Uninformative Prior\", 0.01, \"1\"],\n","#     3: [\"Medium Informative Prior\", 0.01, \"2\"],\n","#     4: [\"High Informative Prior\", 0.01, \"3\"],\n","#     5: [\"High Informative Prior\", 0.0033, \"3\"]\n","# }\n","\n","\n","\n","\n","now = datetime.now()\n","dt_string = now.strftime(\"%Y%m%d_%H%M%S\")\n","\n","\n","\n","basepath = os.path.join(PATH, 'runs_5action', f\"prior_{pc}\", folder_name+dt_string)\n","results_path = os.path.join(basepath, 'Results')\n","\n","log = os.path.join(basepath, \"log.txt\")\n","\n","if not os.path.isdir(basepath):\n","    os.makedirs(basepath)\n","if not os.path.isdir(results_path):\n","    os.makedirs(results_path)\n","\n","printf(f\"Folder: {basepath}\", log)\n","\n","if safe_padding:\n","  printf(f\"\\n#############################\\n\"\n","        f\"safe_padding: {safe_padding}\\n\"\n","        f\"number_of_runs: {number_of_runs}\\n\"\n","        f\"max_iterations: {max_iterations}\\n\"\n","        f\"discount_factor_Q: {discount_factor_Q}\\n\"\n","        f\"alpha: {alpha}\\n\"\n","        f\"observation_radius: {observation_radius}\\n\"\n","        f\"temp: {temp}\\n\"\n","        f\"prior_choice: {prior_choice}\\n\"\n","        f\"critical_threshold: {critical_threshold}\\n\"\n","        f\"choice_of_C: {choice_of_C}\\n\"\n","        f\"#############################\\n\", log)\n","else:\n","  printf(f\"\\n#############################\\n\"\n","        f\"safe_padding: {safe_padding}\\n\"\n","        f\"number_of_runs: {number_of_runs}\\n\"\n","        f\"max_iterations: {max_iterations}\\n\"\n","        f\"discount_factor_Q: {discount_factor_Q}\\n\"\n","        f\"alpha: {alpha}\\n\"\n","        f\"observation_radius: {observation_radius}\\n\"\n","        f\"temp: {temp}\\n\"\n","        f\"prior_choice: {prior_choice}\\n\"\n","        f\"critical_threshold: {critical_threshold}\\n\"\n","        f\"choice_of_C: {choice_of_C}\\n\"\n","        f\"Q-LEARNING ONLY!!!!!!!!!!!!!!!!!\\n\"\n","        f\"#############################\\n\", log)\n","tests = 5\n","printf(f\"You want {tests} tests.\", log)\n","\n","save_runs = 100\n","printf(f\"Breakpoint will be saved every {save_runs} steps\", log)"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"pvSMZ9BTqU4O","executionInfo":{"status":"ok","timestamp":1691596200422,"user_tz":300,"elapsed":240,"user":{"displayName":"David Wang","userId":"05066022198652520596"}}},"outputs":[],"source":["#@title Functions\n","\n","# save_ragged\n","def stack_ragged(array_list, axis=0):\n","    lengths = [np.shape(a)[axis] for a in array_list]\n","    idx = np.cumsum(lengths[:-1])\n","    stacked = np.concatenate(array_list, axis=axis)\n","    return stacked, idx\n","\n","def save_stacked_array(fname, array_list, axis=0):\n","    stacked, idx = stack_ragged(array_list, axis=axis)\n","    np.savez(fname, stacked_array=stacked, stacked_index=idx)\n","\n","def load_stacked_arrays(fname, axis=0):\n","    npzfile = np.load(fname)\n","    idx = npzfile['stacked_index']\n","    stacked = npzfile['stacked_array']\n","    return np.split(stacked, idx, axis=axis)\n","\n","def automaton(u_val,last_automaton_state):\n","    #1 is unsafe and 2 is target\n","    #If we were on a neutral state\n","    if last_automaton_state == 0:\n","        next_automaton_state = u_val\n","    else: #We were already either unsafe or target\n","        next_automaton_state = last_automaton_state\n","    return next_automaton_state\n","\n","def take_action_m(current_location,action_indx,is_det,u):\n","    next_location = current_location.copy()\n","    if (not is_det):\n","        if (np.random.uniform() > .95):\n","            action_indx = np.floor(5*np.random.uniform())\n","    if action_indx == 0: #Right\n","        next_location[1] = current_location[1]+1\n","    elif action_indx == 1: #Up\n","        next_location[0] = current_location[0]-1\n","    elif action_indx == 2: #Left\n","        next_location[1] = current_location[1]-1\n","    elif action_indx == 3: #Down\n","        next_location[0] = current_location[0]+1\n","    # Else if action is 4, Stay.\n","    if next_location[0] > 19:\n","       next_location[0] = 19\n","    if next_location[0] < 0:\n","       next_location[0] = 0\n","    if next_location[1] > 19:\n","       next_location[1] = 19\n","    if next_location[1] < 0:\n","       next_location[1] = 0\n","    next_location[2] = automaton(u[next_location[0],next_location[1]],current_location[2])\n","    return next_location\n","\n","def take_action_m_boundary(current_location,action_indx,is_det,u):\n","    out_of_bounds = False\n","    next_location = current_location.copy()\n","    if (not is_det):\n","        if (np.random.uniform() > .95):\n","            action_indx = np.floor(5*np.random.uniform())\n","    if action_indx == 0: #Right\n","        next_location[1] = current_location[1]+1\n","    elif action_indx == 1: #Up\n","        next_location[0] = current_location[0]-1\n","    elif action_indx == 2: #Left\n","        next_location[1] = current_location[1]-1\n","    elif action_indx == 3: #Down\n","        next_location[0] = current_location[0]+1\n","    # Else if action is 4, Stay.\n","    if next_location[0] > 19:\n","       next_location[0] = 19\n","       out_of_bounds = True\n","    if next_location[0] < 0:\n","       next_location[0] = 0\n","       out_of_bounds = True\n","    if next_location[1] > 19:\n","       next_location[1] = 19\n","       out_of_bounds = True\n","    if next_location[1] < 0:\n","       next_location[1] = 0\n","       out_of_bounds = True\n","    next_location[2] = automaton(u[next_location[0],next_location[1]],current_location[2])\n","    return next_location,out_of_bounds\n","\n","#For vectorizing local_U_update_fixed_actions\n","def take_actions_boundary_det(current_location,u):\n","    out_of_bounds = np.zeros(5)\n","    next_locations = np.tile(current_location, (5,1))\n","\n","    action_to_movement = np.array([[0,1],[-1,0],[0,-1],[1,0],[0,0]])\n","    next_locations[:,0:2] += action_to_movement[[0,1,2,3,4]]\n","\n","    #Couldnt figure out a good way around this loop\n","    for i in np.arange(5):\n","        if next_locations[i,0] > 19:\n","            next_locations[i,0] = 19\n","            out_of_bounds[i] = True\n","        if next_locations[i,0] < 0:\n","            next_locations[i,0] = 0\n","            out_of_bounds[i] = True\n","        if next_locations[i,1] > 19:\n","            next_locations[i,1] = 19\n","            out_of_bounds[i] = True\n","        if next_locations[i,1] < 0:\n","            next_locations[i,1] = 0\n","            out_of_bounds[i] = True\n","        next_locations[i,2] = automaton(u[next_locations[i,0],next_locations[i,1]],current_location[2])\n","    return next_locations,out_of_bounds\n","\n","def take_action_m_direction(current_location,action_indx,is_det,u):\n","    next_location = current_location.copy()\n","    if (not is_det):\n","        if (np.random.uniform() > .95):\n","            action_indx = np.int(5*np.random.uniform())\n","    if action_indx == 0: #Right\n","        next_location[1] = current_location[1]+1\n","    elif action_indx == 1: #Up\n","        next_location[0] = current_location[0]-1\n","    elif action_indx == 2: #Left\n","        next_location[1] = current_location[1]-1\n","    elif action_indx == 3: #Down\n","        next_location[0] = current_location[0]+1\n","    # Else if action is 4, Stay.\n","    direction_taken = action_indx\n","    if next_location[0] > 19:\n","       next_location[0] = 19\n","       direction_taken = 4\n","    if next_location[0] < 0:\n","       next_location[0] = 0\n","       direction_taken = 4\n","    if next_location[1] > 19:\n","       next_location[1] = 19\n","       direction_taken = 4\n","    if next_location[1] < 0:\n","       next_location[1] = 0\n","       direction_taken = 4\n","    next_location[2] = automaton(u[next_location[0],next_location[1]],current_location[2])\n","    return next_location,direction_taken\n","\n","#Reward function\n","def Q_r(next_state):\n","    if next_state[2] == 2:\n","        return 1\n","    else:\n","        return 0\n","\n","#Local risk calcuation with fixed actions\n","def local_U_update_fixed_actions(current_state,neighbours,unsafe_states,depth,ps_delta,min_actions,out_of_bounds_vec,next_state_indx_vec,in_neighbours_vec,current_out_of_bounds,current_next_states_indx_vec,current_in_neighbours_vec,U_start):\n","    discount = 1\n","    U = U_start.copy()\n","\n","    #First depth-1 steps at once, with actions given by min_actions\n","    for d in np.arange(depth-1):\n","        actions = min_actions[d,:]\n","        sums=discount*ps_delta[neighbours[:,0],neighbours[:,1],actions,:]*U[next_state_indx_vec[:,:]]*(out_of_bounds_vec[:,:] == 0)*in_neighbours_vec[:,:]\n","        U = np.sum(sums, axis = 1)\n","\n","        #Ensure U is 1 for unsafe states.\n","        U[unsafe_states] = 1\n","\n","    #FINAL STEP (fixed all actions)\n","    sums1=discount*ps_delta[current_state[0],current_state[1],:,:]*U[current_next_states_indx_vec[:]]*(current_out_of_bounds == 0)*current_in_neighbours_vec\n","\n","    U_delta = np.sum(sums1,1)\n","    return U_delta\n","\n","#Variance on Expected Risk Calculation\n","def risk_variance(current_state,neighbours,unsafe_states,num_neighbours,depth,ps,cov,min_actions,U_s_a,out_of_bounds_vec,next_state_indx_vec,in_neighbours_vec,current_out_of_bounds,current_next_states_indx_vec,current_in_neighbours_vec,U_start):\n","    #Covariance Matrix based on lexicographic ordering of state,action,state on\n","    #transition probabilities\n","    #We only represent the non-zero entries in the covariance matrix.\n","    #So cov(q1,q2,a,direction1,direction2) gives the covariance between the\n","    #transitions probability (q1,q2) (a)-> direction1(q1,q2) and (q1,q2) (a)-> direction2(q1,q2)\n","    #Maybe we should maintain and update this rather than recalculating at\n","    #every step.\n","\n","    #We choose delta for numerical differentiation, standard detla = 0.001\n","    delta = 0.001\n","\n","    #Just calculate the relevant ones (transition probs starting in\n","    #neighbouring states - these are the only ones used in risk\n","    variance_U = np.zeros(5)\n","\n","    #Now calculate variance\n","    #Do simultaneously for each first_action\n","    for neigh in np.arange(num_neighbours):\n","        for a in np.arange(5):\n","            #For storing gradients\n","            grad = np.zeros((5,5))\n","            for d in np.arange(5):\n","                #Calculate derivative wrt. p_neigh_a_d\n","                ps_delta = ps.copy()\n","                ps_delta[neighbours[neigh,0],neighbours[neigh,1],a,d] = \\\n","                    ps_delta[neighbours[neigh,0],neighbours[neigh,1],a,d] + delta\n","\n","                #Replicate local_U_update calculation but with actions\n","                #according to min_actions.\n","\n","                U_delta = local_U_update_fixed_actions(current_state,neighbours,unsafe_states,depth,ps_delta,min_actions,out_of_bounds_vec,next_state_indx_vec,in_neighbours_vec,current_out_of_bounds,current_next_states_indx_vec,current_in_neighbours_vec,U_start)\n","                #Row? vector of gradients for risk after each first_action, wrt\n","                #p_neigh_a_d.\n","                #Each column contains the gradients wrt p_neigh_a_allds for the\n","                #risk after a particular action\n","                grad[d,:] = (U_delta - U_s_a)/delta\n","\n","\n","            #Add contribution to variance. @ is matrix multiplication\n","            for first_action in np.arange(5):\n","                variance_U[first_action] = variance_U[first_action] + np.transpose(grad[:,first_action]) @ cov[neighbours[neigh,0],neighbours[neigh,1],a,:,:] @ grad[:,first_action]\n","    return variance_U\n","\n","#Local Risk Calculation\n","def local_U_update(current_state,neighbours,depth,u,ps,cov):\n","    discount = 1\n","    num_neighbours = np.shape(neighbours)[0]\n","\n","    #Pre-Calculate as Much as We Can.\n","    U_start = np.zeros(num_neighbours)\n","    unsafe_states = neighbours[:,2] == 1\n","    U_start[unsafe_states] = 1\n","\n","    #Pre-calculate next_state, next_state_indx, out_of_bounds and in_neighbours\n","    #for each neigh and direction\n","    next_state_vec = np.zeros((num_neighbours,5,3),dtype=np.int8)\n","    out_of_bounds_vec = np.zeros((num_neighbours,5),np.int8)\n","    next_state_indx_vec = np.zeros((num_neighbours,5),np.int8) #Defaults to 0 if not in neighbours. Won't influence calculation\n","    in_neighbours_vec = np.ones((num_neighbours,5),np.int8)\n","    for neigh in np.arange(num_neighbours):\n","        for direction in np.arange(5):\n","            next_state,out_of_bounds = take_action_m_boundary(neighbours[neigh],direction,True,u)\n","            next_state_vec[neigh,direction] = next_state\n","            out_of_bounds_vec[neigh,direction] = out_of_bounds\n","\n","            (next_state_indx_array,) = np.where(np.all(neighbours == next_state, axis = 1))\n","\n","            if len(next_state_indx_array) == 0:\n","                in_neighbours_vec[neigh,direction] = 0\n","                #next_state_indx_vec defaults to 0\n","            else:\n","                #in_neighbours defaults to 1\n","                next_state_indx_vec[neigh,direction] = next_state_indx_array[0]\n","\n","    #Also pre-calculate next_states, next_states_indx, out_of_bounds and in_neighbours\n","    #For the final step, with CURRENT STATE and All Directions\n","    current_next_states,current_out_of_bounds = take_actions_boundary_det(current_state,u) #Note that out_of_bounds here is 1 dimensional, but is used in the multiplication as 2 dimensional, because it is the same over actions.\n","    current_next_states_indx_vec = np.zeros(5,dtype = np.int8) #Same comment\n","    current_in_neighbours_vec = np.ones(5,dtype=np.int8) #Same comment\n","    #Now I want to get the list of the indices of current_next_states in neighbours.\n","    for direction in np.arange(5):\n","        (current_next_state_indx_array,) = np.where(np.all(neighbours == current_next_states[direction,:], axis = 1))\n","        if len(current_next_state_indx_array) == 0:\n","            current_in_neighbours_vec[direction] = 0\n","        else:\n","            current_next_states_indx_vec[direction] = current_next_state_indx_array[0]\n","\n","\n","    U_temp = U_start.copy()\n","    U = U_start.copy()\n","\n","    #First depth-1 steps (minimum expected risk action)\n","    #Saves the minimum expected risk action for each state.\n","    min_actions = np.zeros((depth-1,num_neighbours),dtype=np.int8)\n","    for d in np.arange(depth-1):\n","        for neigh in np.arange(num_neighbours):\n","            sums = np.zeros((5,5))\n","            for direction in np.arange(5):\n","                next_state = next_state_vec[neigh,direction]\n","                out_of_bounds = out_of_bounds_vec[neigh,direction]\n","                next_state_indx = next_state_indx_vec[neigh,direction]\n","                in_neighbours = in_neighbours_vec[neigh,direction]\n","\n","                sums[:,direction]=discount*ps[neighbours[neigh,0],neighbours[neigh,1],:,direction]*U[next_state_indx]*(out_of_bounds == 0)*in_neighbours\n","\n","            action_risks = np.sum(sums,1)\n","            chosen_action = np.argmin(action_risks)\n","            U_temp[neigh] = action_risks[chosen_action]\n","            min_actions[d,neigh] = chosen_action\n","\n","        U = U_temp.copy()\n","        #Ensure U is 1 for unsafe states.\n","        U[unsafe_states] = 1\n","        U_temp[unsafe_states] = 1\n","\n","    #Final Step (fixed action) (just current state)\n","    sums1=discount*ps[current_state[0],current_state[1],:,:]*U[current_next_states_indx_vec[:]]*(current_out_of_bounds == 0)*current_in_neighbours_vec\n","    U_s_a = np.sum(sums1,1)\n","\n","    variance_U = risk_variance(current_state,neighbours,unsafe_states,num_neighbours,depth,ps,cov,min_actions,U_s_a,out_of_bounds_vec,next_state_indx_vec,in_neighbours_vec,current_out_of_bounds,current_next_states_indx_vec,current_in_neighbours_vec,U_start)\n","    return U_s_a,variance_U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxDbQTsoreMH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c52ff6fe-aead-4229-c8d4-437c8338bc26","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","-------- Experiment (1 of 5) ---------\n","Name: bridge_5action_Pmax0.01_CThesisDecreasing_PriorUnin_experiment1\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1500 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Run Number: 1\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-3e70ca9bf48b>:113: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  action_indx = np.int(5*np.random.uniform())\n","  0%|          | 1/1500 [00:11<4:51:54, 11.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Run Number: 2\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 2/1500 [00:22<4:33:50, 10.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Run Number: 3\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 3/1500 [00:23<2:45:07,  6.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Run Number: 4\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 4/1500 [00:35<3:38:37,  8.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Run Number: 5\n"]}],"source":["#@title Training\n","\n","file_start_num = 1\n","cnt = 1\n","for experiment_number in range(file_start_num, file_start_num+int(tests)):\n","    experiment_name = \"bridge_5action_Pmax{Pmax}_C{C}_Prior{prior}_experiment{number}\".format(\n","        Pmax=critical_threshold, prior=prior_choice[0:4], C=choice_of_C, number=experiment_number)\n","    printf(f\"\\n-------- Experiment ({cnt} of {tests}) ---------\\nName: {experiment_name}\", log)\n","    cnt += 1\n","\n","    ##Defining the area\n","    X_movable_limit = 20\n","    Y_movable_limit = 20\n","    X=np.linspace(1,X_movable_limit,X_movable_limit)\n","    Y=np.linspace(1,Y_movable_limit,Y_movable_limit)\n","    [gridx,gridy]=np.meshgrid(X,Y)\n","\n","    ##State Labels\n","    u=np.zeros([20,20])\n","    u[0:7,0:20]=2\n","    u[8:12,0:8]=1\n","    u[8:12,11:20]=1\n","\n","    ##Initialize Counters/Trackers\n","    it_run_num=1\n","    number_of_fails=0\n","    failed_path=[]\n","    fail_history=[]\n","    success_history=[]\n","    number_of_successes=0\n","    path_history=[]\n","    successful_runs = np.zeros(number_of_runs)\n","\n","    ##Q function. A 4-dim matrix (action,state(X, Y),automaton_state)\n","    total_number_of_actions=5\n","    Q=np.zeros((total_number_of_actions,X_movable_limit,Y_movable_limit,3)) #Is there a point having the automaton_state here? Maybe just for generality?\n","\n","    #State Counts\n","    state_count=np.zeros((X_movable_limit,Y_movable_limit))\n","    state_count[19,0] = 1\n","\n","    #Defining the Prior\n","    if prior_choice == \"Uninformative Prior\":\n","        state_action_direction_prior=np.zeros((20,20,5,5))\n","        for action_indx in np.arange(5):\n","            for x in np.arange(0,X_movable_limit):\n","                for y in np.arange(0,Y_movable_limit):\n","                    for direction in np.arange(0,5):\n","                        poss_next_state,out_of_bounds = take_action_m_boundary([x,y,1],direction,True,u)\n","                        if out_of_bounds == False:\n","                            state_action_direction_prior[x,y,action_indx,direction]=1\n","        state_action_direction_posterior = state_action_direction_prior\n","\n","    if prior_choice == \"Medium Informative Prior\":\n","        state_action_direction_prior=np.zeros((20,20,5,5))\n","        for action_indx in np.arange(5):\n","            for x in np.arange(0,X_movable_limit):\n","                for y in np.arange(0,Y_movable_limit):\n","                    for direction in np.arange(0,5):\n","                        poss_next_state,out_of_bounds = take_action_m_boundary([x,y,1],direction,True,u)\n","                        if out_of_bounds == False:\n","                            if action_indx == direction:\n","                                state_action_direction_prior[x,y,action_indx,direction]=12\n","                            else:\n","                                state_action_direction_prior[x,y,action_indx,direction]=1\n","        state_action_direction_posterior = state_action_direction_prior\n","\n","    if prior_choice == \"High Informative Prior\":\n","        state_action_direction_prior=np.zeros((20,20,5,5))\n","        for action_indx in np.arange(5):\n","            for x in np.arange(0,X_movable_limit):\n","                for y in np.arange(0,Y_movable_limit):\n","                    for direction in np.arange(0,5):\n","                        poss_next_state,out_of_bounds = take_action_m_boundary([x,y,1],direction,True,u)\n","                        if out_of_bounds == False:\n","                            if action_indx == direction:\n","                                state_action_direction_prior[x,y,action_indx,direction]=96\n","                            else:\n","                                state_action_direction_prior[x,y,action_indx,direction]=1\n","        state_action_direction_posterior = state_action_direction_prior\n","\n","    #State_action_prior: similar to the above, based on the prior given above\n","    state_action_prior=np.sum(state_action_direction_prior,3)\n","    state_action_posterior = state_action_prior\n","\n","    #Expected transition probabilities\n","    ps = np.divide(state_action_direction_prior, np.expand_dims(state_action_prior,3))\n","\n","    #Covariance Matrix: cov(q1,q2,action,:,:) is the 5*5 covariance matrix for\n","    #the dirichlet for taking action at state (q1,q2)\n","    cov = np.zeros((20,20,5,5,5))\n","    for q1 in np.arange(0,20):\n","        for q2 in np.arange(0,20):\n","            for a in np.arange(0,5):\n","                for direction_i in np.arange(0,5):\n","                    for direction_j in np.arange(0,5):\n","                        cov[q1,q2,a,direction_i,direction_j] = ((direction_i == direction_j)*ps[q1,q2,a,direction_i] - ps[q1,q2,a,direction_i]*ps[q1,q2,a,direction_j]) \\\n","                          / (state_action_posterior[q1,q2,a] + 1)\n","\n","    #Defining the parameter C as a function of state_count\n","    if choice_of_C == \"ThesisDecreasing\":\n","        def C_function(cur_state_count):\n","            return 0.7*max((24 - cur_state_count)/25,0) + 0.3/(1 + cur_state_count)\n","\n","    if choice_of_C[0:5] == \"Fixed\":\n","        c = float(choice_of_C[5:9])\n","        def C_function(cur_state_cout):\n","            return c\n","\n","    if choice_of_C[0:5] == \"Slope\":\n","        num = int(choice_of_C[5:7])\n","        def C_function(cur_state_count):\n","            return 0.7*max(((num-1) - cur_state_count)/num,0) + 0.3/(1 + cur_state_count)\n","\n","    #Train Agent\n","    start_time = time.time()\n","    for run_num in tqdm(np.arange(1, number_of_runs + 1)):\n","        current_state = np.array([19,0,0]) #In the product MDP\n","        current_path = np.expand_dims(current_state,0) #Add a dimension so we can keep a list of states\n","        print('Run Number: ' + str(run_num))\n","        it_num = 1\n","        while (current_state[-1]!=2) and (it_num <= max_iterations):\n","            #SOME DEBUGGING PRINTS\n","            #print('Iteration Number: ' + str(it_num))\n","            #print('Current State: ' + str(current_state))\n","            it_num = it_num + 1\n","            it_run_num = it_run_num+1\n","\n","            if safe_padding:\n","                depth = 2 #Must be <= observation radius\n","                old_neighbours=np.expand_dims(current_state,0) #Add a dimension so we can keep a list of states\n","                neighbours=np.array([]).astype(np.int8).reshape(0,3) #CAREFUL IF THE SIZE OF THE AREA IS LARGER THAN 128\n","                #Expand neighbours one at a time until covering the\n","                #Obervation_radius: make sure it is unique.\n","                #NOTE: Neighbours is in the product MDP\n","                for i in np.arange(observation_radius):\n","                    for current_exploring in np.arange(np.size(old_neighbours,0)):\n","                        for action in np.arange(5):\n","                            neighbours= np.vstack([neighbours,take_action_m(old_neighbours[current_exploring],action,True,u)])\n","                        neighbours=np.unique(neighbours,axis=0)\n","                    old_neighbours=np.vstack([old_neighbours,neighbours])\n","                    old_neighbours=np.unique(old_neighbours,axis=0)\n","\n","                #RISK AND VARIANCE CALCULATION!\n","                U,variance_U=local_U_update(current_state,neighbours,depth,u,ps,cov)\n","\n","                #Defining the parameter C for risk-averseness based on state_count\n","                C = C_function(state_count[current_state[0],current_state[1]])\n","\n","                #Perform Cantelli Bound calculation\n","                P_a = U + np.sqrt((variance_U*C)/(1-C))\n","\n","                #(weird formatting because np.nonzero returns index tuples)\n","                (acceptable_actions,)=np.nonzero(P_a<critical_threshold)\n","                #If nothing is acceptable, then just choose minimum U.\n","                if acceptable_actions.size == 0:\n","                    acceptable_actions = np.nonzero(U == np.amin(U))\n","\n","            available_Qs = np.zeros(5)\n","            if safe_padding == 1:\n","                for each_action in acceptable_actions:\n","                    available_Qs[each_action]=Q[each_action,current_state[0],current_state[1],current_state[2]]\n","                for each_action in np.setdiff1d(np.arange(5),acceptable_actions,assume_unique=True):\n","                    available_Qs[each_action]=Q[each_action,current_state[0],current_state[1],current_state[2]] - 300\n","            else:\n","                for each_action in np.arange(5):\n","                    available_Qs[each_action]=Q[each_action,current_state[0],current_state[1],current_state[2]]\n","\n","            #Boltzmann rational\n","            expo=np.exp(available_Qs/temp)\n","            probabs=expo/sum(expo)\n","\n","            #Select an action\n","            actions=np.arange(5)\n","            selected_action = np.random.choice(actions, p=probabs)\n","\n","            #Take that action\n","            next_state,direction_taken=take_action_m_direction(current_state,selected_action,False,u)\n","\n","            #UPDATES\n","            #Update posterior by adding counts\n","            state_action_direction_posterior[current_state[0],current_state[1],selected_action,direction_taken]= \\\n","                state_action_direction_posterior[current_state[0],current_state[1],selected_action,direction_taken] + 1\n","\n","            state_action_posterior[current_state[0],current_state[1],selected_action] = \\\n","                state_action_posterior[current_state[0],current_state[1],selected_action] + 1\n","            #Update Means\n","            ps[current_state[0],current_state[1],selected_action,:] = \\\n","                state_action_direction_posterior[current_state[0],current_state[1],selected_action,:] / state_action_posterior[current_state[0],current_state[1],selected_action]\n","            #Update Covariance Matrix\n","            for direction_i in np.arange(5):\n","                for direction_j in np.arange(5):\n","                    cov[current_state[0],current_state[1],selected_action,direction_i,direction_j] = ((direction_i == direction_j)*ps[current_state[0],current_state[1],selected_action,direction_i] - ps[current_state[0],current_state[1],selected_action,direction_i]*ps[current_state[0],current_state[1],selected_action,direction_j]) \\\n","                        / (state_action_posterior[current_state[0],current_state[1],selected_action] + 1)\n","\n","            #Update Q function\n","            current_Qs=Q[:,next_state[0],next_state[1],next_state[2]]\n","\n","            Q[selected_action,current_state[0],current_state[1],current_state[2]] = (1-alpha)* \\\n","                Q[selected_action,current_state[0],current_state[1],current_state[2]] + alpha * \\\n","                (Q_r(next_state) + discount_factor_Q*np.amax(current_Qs))\n","\n","            #Update state counts to reflect moving to next state\n","            state_count[next_state[0],next_state[1]] = state_count[next_state[0],next_state[1]] + 1\n","            current_path=np.vstack([current_path,next_state])\n","\n","            #DISPLAY (AND TERMINATE IF FAILED)\n","            if next_state[2] == 1:\n","                number_of_fails = number_of_fails + 1\n","                #print('-------fail-------')\n","                #print('Current State: ' + str(current_state))\n","                #print('Next State: ' + str(next_state))\n","                #print('Neighbours: ' + str(neighbours))\n","                #print('U: ' + str(U))\n","                #print('Selected Action:' + str(selected_action))\n","                break\n","            elif next_state[2] == 2:\n","                #print('+++++++success+++++++')\n","                number_of_successes = number_of_successes + 1\n","                #Keep a record of which runs were successful.\n","                successful_runs[run_num - 1] = 1\n","\n","            #Update current state\n","            current_state = next_state.copy()\n","\n","        #Add run to paths.\n","        path_history.append(current_path)\n","\n","        #Cumulative total of number of successes.\n","        fail_history.append(number_of_fails)\n","        success_history.append(number_of_successes)\n","\n","\n","        if run_num % int(save_runs) == 0:\n","          printf(f\"\\nSaving breakpoint @ experiment number <{experiment_number}> | run <{run_num}>\", log)\n","          np.save(os.path.join(results_path, experiment_name + \"_failHistory\"), fail_history)\n","          np.save(os.path.join(results_path, experiment_name + \"_successHistory\"), success_history)\n","          np.save(os.path.join(results_path, experiment_name + \"_successfulRuns\"), successful_runs)\n","          np.save(os.path.join(results_path, experiment_name + \"_Q\"), Q)\n","          save_stacked_array(os.path.join(results_path, experiment_name + \"_pathHistory\"), path_history, axis=0)\n","\n","    # Prints\n","    printf(f\"Time Elapsed: {(time.time()-start_time):.2f} secs ({(time.time()-start_time)/60:.2f} mins)\", log)\n","    printf(f\"Number of Successes: {str(number_of_successes)}\", log)\n","    printf(f\"Number of Failures: {str(number_of_fails)}\", log)\n","\n","    # Save Results!\n","    np.save(os.path.join(results_path, experiment_name + \"_failHistory\"), fail_history)\n","    np.save(os.path.join(results_path, experiment_name + \"_successHistory\"), success_history)\n","    np.save(os.path.join(results_path, experiment_name + \"_successfulRuns\"), successful_runs)\n","    np.save(os.path.join(results_path, experiment_name + \"_Q\"), Q)\n","    save_stacked_array(os.path.join(results_path, experiment_name + \"_pathHistory\"), path_history, axis=0)\n","    printf(f\"\\nTraining Completed.\\nEnding experiment number <{experiment_number}>\", log)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}